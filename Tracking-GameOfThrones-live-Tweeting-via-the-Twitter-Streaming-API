
.ipynb

@@ -1,1239 +0,0 @@
{
 "metadata": {
  "name": "",
  "signature": "sha256:69f8bd3a63a1ab45d6489061c449ab6ea8d78e75cafbd91c4b0f7749eebb3315"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tracking #GameOfThrones live-Tweeting via the Twitter Streaming API"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What the code currently does:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Taps Twitter's Streaming API and collects tweets with the hashtag #GameOfThrones\n",
      "* Outputs these tweets and their metadata to a json file.\n",
      "* Processes the records and generates metadata about the collection of tweets\n",
      "\n",
      "This code was adapted from <a href=\"http://nbviewer.ipython.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/__Understanding%20the%20Reaction%20to%20Amazon%20Prime%20Air.ipynb\">an example from Russel's <i>Mining the Social Web</i></a>."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What the code needs to do:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Output shit to a .csv with just the data we need for parsing in D3.js\n",
      "* Consider how/whether to include tweets from other hashtags in the mix-- adjusting the query parameters?\n",
      "* Be able to run on a chron so I don't have to sit at my computer watching this for an hour, and so I can schedule collections during specific airings\n",
      "* More automation to get from Twitter -> browser"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Python Dependencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* The *twitter* package trivializes the process of tapping into Twitter's Streaming API for easily capturing tweets from the firehose\n",
      "* The *pandas* package provides a highly-performant \"spreadsheet-like interface\" into large collections of records such as tweets\n",
      "* The *nltk* packages provides some handy functions for processing natural language (the \"140 characters\" of content) in the tweets\n",
      "\n",
      "You can easily install these packages in a terminal with *pip install twitter pandas nltk*, or you can install them from within IPython Notebook by using \"Bash magic\". Bash magic is just a way of running Bash commands from within a notebook as shown below where the first line of a cell prefixed with *%%bash*."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "pip install twitter pandas nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied (use --upgrade to upgrade): twitter in /anaconda/lib/python2.7/site-packages\n",
        "Requirement already satisfied (use --upgrade to upgrade): pandas in /anaconda/lib/python2.7/site-packages\n",
        "Requirement already satisfied (use --upgrade to upgrade): nltk in /anaconda/lib/python2.7/site-packages\n",
        "Cleaning up...\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Using the Twitter Streaming API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The code below show you how to create a connection to <a href=\"https://dev.twitter.com/docs/streaming-apis\">Twitter's Streaming API</a> and filter the firehose for tweets containing keywords. For simplicity, each tweet is saved in a newline-delimited file as a JSON document."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import io\n",
      "import json\n",
      "import twitter\n",
      "\n",
      "# XXX: Go to http://twitter.com/apps/new to create an app and get values\n",
      "# for these credentials that you'll need to provide in place of these\n",
      "# empty string values that are defined as placeholders.\n",
      "#\n",
      "# See https://vimeo.com/79220146 for a short video that steps you\n",
      "# through this process\n",
      "#\n",
      "# See https://dev.twitter.com/docs/auth/oauth for more information \n",
      "# on Twitter's OAuth implementation.\n",
      "\n",
      "CONSUMER_KEY = 'ttxK07hMMny3Z07lXDHlRAm23'\n",
      "CONSUMER_SECRET = 'GSsi75ac3JIBmX7qkoAtmiu7rqMAXYtSW7XfqB2zxsZH2mXABj'\n",
      "OAUTH_TOKEN = '146874162-pLAATuDgCgBB0f2Q9TSTzoelT9itFBYZRvSYVnpL'\n",
      "OAUTH_TOKEN_SECRET = '8lT497VadS7TQXuSURFEmaSun9Sb0qgm1UfUXGLF9vN0m'\n",
      "\n",
      "# The keyword query\n",
      "\n",
      "QUERY = 'GameOfThrones'\n",
      "\n",
      "# The file to write output as newline-delimited JSON documents\n",
      "OUT_FILE = QUERY + \".json\"\n",
      "\n",
      "\n",
      "# Authenticate to Twitter with OAuth\n",
      "\n",
      "auth = twitter.oauth.OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
      "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
      "\n",
      "# Create a connection to the Streaming API\n",
      "\n",
      "twitter_stream = twitter.TwitterStream(auth=auth)\n",
      "\n",
      "\n",
      "print 'Filtering the public timeline for \"{0}\"'.format(QUERY)\n",
      "\n",
      "# See https://dev.twitter.com/docs/streaming-apis on keyword parameters\n",
      "\n",
      "stream = twitter_stream.statuses.filter(track=QUERY)\n",
      "\n",
      "# Write one tweet per line as a JSON document. \n",
      "\n",
      "with io.open(OUT_FILE, 'w', encoding='utf-8', buffering=1) as f:\n",
      "    for tweet in stream:\n",
      "        f.write(unicode(u'{0}\\n'.format(json.dumps(tweet, ensure_ascii=False))))\n",
      "        print tweet['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Output to D3"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This needs to be done somehow. Code goes here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analyze"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is also a to do: there's a lot of analysis done in the example using panda and NLP: that could build some cool features for side-bar metadata around the body of tweets. We can mess with that later. First we need to get something that d3 can use."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "# A text file with one tweet per line\n",
      "\n",
      "DATA_FILE = \"GameOfThrones_6-1.json\"\n",
      "\n",
      "# Build a JSON array\n",
      "\n",
      "data = \"[{0}]\".format(\",\".join([l for l in open(DATA_FILE).readlines()]))\n",
      "\n",
      "# Create a pandas DataFrame (think: 2-dimensional table) to get a \n",
      "# spreadsheet-like interface into the data\n",
      "\n",
      "df = pd.read_json(data, orient='records')\n",
      "\n",
      "print \"Successfully imported\", len(df), \"tweets\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Successfully imported 35038 tweets\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can look at the data in the pandas columnar view:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Printing a DataFrame shows how pandas exposes a columnar view of the data\n",
      "\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    contributors coordinates          created_at  \\\n",
        "0            NaN        None 2014-06-02 00:15:00   \n",
        "1            NaN        None 2014-06-02 00:15:01   \n",
        "2            NaN        None 2014-06-02 00:15:02   \n",
        "3            NaN        None 2014-06-02 00:15:03   \n",
        "4            NaN        None 2014-06-02 00:15:03   \n",
        "5            NaN        None 2014-06-02 00:15:04   \n",
        "6            NaN        None 2014-06-02 00:15:04   \n",
        "7            NaN        None 2014-06-02 00:15:04   \n",
        "8            NaN        None 2014-06-02 00:15:05   \n",
        "9            NaN        None 2014-06-02 00:15:07   \n",
        "10           NaN        None 2014-06-02 00:15:07   \n",
        "11           NaN        None 2014-06-02 00:15:08   \n",
        "12           NaN        None 2014-06-02 00:15:09   \n",
        "13           NaN        None 2014-06-02 00:15:08   \n",
        "14           NaN        None 2014-06-02 00:15:09   \n",
        "15           NaN        None 2014-06-02 00:15:09   \n",
        "16           NaN        None 2014-06-02 00:15:10   \n",
        "17           NaN        None 2014-06-02 00:15:10   \n",
        "18           NaN        None 2014-06-02 00:15:11   \n",
        "19           NaN        None 2014-06-02 00:15:13   \n",
        "20           NaN        None 2014-06-02 00:15:13   \n",
        "21           NaN        None 2014-06-02 00:15:14   \n",
        "22           NaN        None 2014-06-02 00:15:13   \n",
        "23           NaN        None 2014-06-02 00:15:14   \n",
        "24           NaN        None 2014-06-02 00:15:15   \n",
        "25           NaN        None 2014-06-02 00:15:19   \n",
        "26           NaN        None 2014-06-02 00:15:21   \n",
        "27           NaN        None 2014-06-02 00:15:21   \n",
        "28           NaN        None 2014-06-02 00:15:21   \n",
        "29           NaN        None 2014-06-02 00:15:22   \n",
        "30           NaN        None 2014-06-02 00:15:22   \n",
        "31           NaN        None 2014-06-02 00:15:23   \n",
        "32           NaN        None 2014-06-02 00:15:27   \n",
        "33           NaN        None 2014-06-02 00:15:27   \n",
        "34           NaN        None 2014-06-02 00:15:28   \n",
        "35           NaN        None 2014-06-02 00:15:30   \n",
        "36           NaN        None 2014-06-02 00:15:32   \n",
        "37           NaN        None 2014-06-02 00:15:33   \n",
        "38           NaN        None 2014-06-02 00:15:33   \n",
        "39           NaN        None 2014-06-02 00:15:34   \n",
        "40           NaN        None 2014-06-02 00:15:37   \n",
        "41           NaN        None 2014-06-02 00:15:37   \n",
        "42           NaN        None 2014-06-02 00:15:37   \n",
        "43           NaN        None 2014-06-02 00:15:39   \n",
        "44           NaN        None 2014-06-02 00:15:40   \n",
        "45           NaN        None 2014-06-02 00:15:41   \n",
        "46           NaN        None 2014-06-02 00:15:44   \n",
        "47           NaN        None 2014-06-02 00:15:44   \n",
        "48           NaN        None 2014-06-02 00:15:45   \n",
        "49           NaN        None 2014-06-02 00:15:46   \n",
        "50           NaN        None 2014-06-02 00:15:46   \n",
        "51           NaN        None 2014-06-02 00:15:46   \n",
        "52           NaN        None 2014-06-02 00:15:50   \n",
        "53           NaN        None 2014-06-02 00:15:52   \n",
        "54           NaN        None 2014-06-02 00:15:52   \n",
        "55           NaN        None 2014-06-02 00:15:54   \n",
        "56           NaN        None 2014-06-02 00:15:54   \n",
        "57           NaN        None 2014-06-02 00:15:56   \n",
        "58           NaN        None 2014-06-02 00:15:57   \n",
        "59           NaN        None 2014-06-02 00:15:58   \n",
        "             ...         ...                 ...   \n",
        "\n",
        "                                             entities  favorite_count  \\\n",
        "0   {u'user_mentions': [{u'indices': [20, 34], u's...               0   \n",
        "1   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "2   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "3   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "4   {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "5   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "6   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "7   {u'user_mentions': [{u'indices': [3, 14], u'sc...               0   \n",
        "8   {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "9   {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "10  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "11  {u'user_mentions': [{u'indices': [12, 21], u's...               0   \n",
        "12  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "13  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "14  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "15  {u'user_mentions': [{u'indices': [60, 74], u's...               0   \n",
        "16  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "17  {u'user_mentions': [{u'indices': [13, 27], u's...               0   \n",
        "18  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "19  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "20  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "21  {u'user_mentions': [{u'indices': [3, 15], u'sc...               0   \n",
        "22  {u'user_mentions': [{u'indices': [50, 64], u's...               0   \n",
        "23  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "24  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "25  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "26  {u'user_mentions': [{u'indices': [3, 12], u'sc...               0   \n",
        "27  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "28  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "29  {u'user_mentions': [{u'indices': [3, 19], u'sc...               0   \n",
        "30  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "31  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "32  {u'user_mentions': [{u'indices': [32, 46], u's...               0   \n",
        "33  {u'user_mentions': [{u'indices': [25, 39], u's...               0   \n",
        "34  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "35  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "36  {u'user_mentions': [{u'indices': [3, 11], u'sc...               0   \n",
        "37  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "38  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "39  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "40  {u'user_mentions': [{u'indices': [12, 26], u's...               0   \n",
        "41  {u'user_mentions': [{u'indices': [12, 16], u's...               0   \n",
        "42  {u'user_mentions': [{u'indices': [3, 12], u'sc...               0   \n",
        "43  {u'user_mentions': [{u'indices': [79, 93], u's...               0   \n",
        "44  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "45  {u'user_mentions': [{u'indices': [48, 59], u's...               0   \n",
        "46  {u'user_mentions': [{u'indices': [37, 51], u's...               0   \n",
        "47  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "48  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "49  {u'user_mentions': [{u'indices': [0, 14], u'sc...               0   \n",
        "50  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "51  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "52  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "53  {u'user_mentions': [{u'indices': [13, 23], u's...               0   \n",
        "54  {u'user_mentions': [], u'media': [{u'expanded_...               0   \n",
        "55  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "56  {u'user_mentions': [{u'indices': [3, 14], u'sc...               0   \n",
        "57  {u'user_mentions': [{u'indices': [70, 84], u's...               0   \n",
        "58  {u'user_mentions': [], u'symbols': [], u'trend...               0   \n",
        "59  {u'user_mentions': [{u'indices': [3, 17], u'sc...               0   \n",
        "                                                  ...             ...   \n",
        "\n",
        "   favorited filter_level   geo                  id              id_str  \\\n",
        "0      False       medium  None  473256432415281153  473256432415281152   \n",
        "1      False       medium  None  473256434835406848  473256434835406848   \n",
        "2      False       medium  None  473256441101295616  473256441101295616   \n",
        "3      False       medium  None  473256441969901568  473256441969901568   \n",
        "4      False       medium  None  473256442481623040  473256442481623040   \n",
        "5      False       medium  None  473256445958303744  473256445958303744   \n",
        "6      False       medium  None  473256446981726208  473256446981726208   \n",
        "7      False       medium  None  473256448731131904  473256448731131904   \n",
        "8      False       medium  None  473256451742646272  473256451742646272   \n",
        "9      False       medium  None  473256458382237696  473256458382237696   \n",
        "10     False       medium  None  473256459942105089  473256459942105088   \n",
        "11     False       medium  None  473256463373066240  473256463373066240   \n",
        "12     False       medium  None  473256466846330880  473256466846330880   \n",
        "13     False       medium  None  473256466334621697  473256466334621696   \n",
        "14     False       medium  None  473256467584524288  473256467584524288   \n",
        "15     False       medium  None  473256470293667841  473256470293667840   \n",
        "16     False       medium  None  473256472357662720  473256472357662720   \n",
        "17     False       medium  None  473256473267818496  473256473267818496   \n",
        "18     False       medium  None  473256476812009472  473256476812009472   \n",
        "19     False       medium  None  473256485690961921  473256485690961920   \n",
        "20     False       medium  None  473256487150968833  473256487150968832   \n",
        "21     False       medium  None  473256487578787842  473256487578787840   \n",
        "22     False       medium  None  473256487406809088  473256487406809088   \n",
        "23     False       medium  None  473256487645872128  473256487645872128   \n",
        "24     False       medium  None  473256492549021696  473256492549021696   \n",
        "25     False       medium  None  473256511905759232  473256511905759232   \n",
        "26     False       medium  None  473256517794549760  473256517794549760   \n",
        "27     False       medium  None  473256518477836288  473256518477836288   \n",
        "28     False       medium  None  473256519988158464  473256519988158464   \n",
        "29     False       medium  None  473256520508248065  473256520508248064   \n",
        "30     False       medium  None  473256524593524736  473256524593524736   \n",
        "31     False       medium  None  473256528963993600  473256528963993600   \n",
        "32     False       medium  None  473256544553807872  473256544553807872   \n",
        "33     False       medium  None  473256545414021120  473256545414021120   \n",
        "34     False       medium  None  473256548186087424  473256548186087424   \n",
        "35     False       medium  None  473256558596325377  473256558596325376   \n",
        "36     False       medium  None  473256566091546624  473256566091546624   \n",
        "37     False       medium  None  473256567878320128  473256567878320128   \n",
        "38     False       medium  None  473256570730467328  473256570730467328   \n",
        "39     False       medium  None  473256572500848640  473256572500848640   \n",
        "40     False       medium  None  473256587533242368  473256587533242368   \n",
        "41     False       medium  None  473256587566395392  473256587566395392   \n",
        "42     False       medium  None  473256588048736258  473256588048736256   \n",
        "43     False       medium  None  473256596328685568  473256596328685568   \n",
        "44     False       medium  None  473256600506208257  473256600506208256   \n",
        "45     False       medium  None  473256601017520129  473256601017520128   \n",
        "46     False       medium  None  473256613810536448  473256613810536448   \n",
        "47     False       medium  None  473256614548754432  473256614548754432   \n",
        "48     False       medium  None  473256619070193665  473256619070193664   \n",
        "49     False       medium  None  473256624573120512  473256624573120512   \n",
        "50     False       medium  None  473256624547987456  473256624547987456   \n",
        "51     False       medium  None  473256625701392384  473256625701392384   \n",
        "52     False       medium  None  473256640163360768  473256640163360768   \n",
        "53     False       medium  None  473256648102797312  473256648102797312   \n",
        "54     False       medium  None  473256651177598976  473256651177598976   \n",
        "55     False       medium  None  473256658387611648  473256658387611648   \n",
        "56     False       medium  None  473256658853175297  473256658853175296   \n",
        "57     False       medium  None  473256664905576449  473256664905576448   \n",
        "58     False       medium  None  473256670307815424  473256670307815424   \n",
        "59     False       medium  None  473256673168330753  473256673168330752   \n",
        "         ...          ...   ...                 ...                 ...   \n",
        "\n",
        "   in_reply_to_screen_name  in_reply_to_status_id  in_reply_to_status_id_str  \\\n",
        "0                     None                    NaN                        NaN   \n",
        "1                     None                    NaN                        NaN   \n",
        "2                     None                    NaN                        NaN   \n",
        "3                     None                    NaN                        NaN   \n",
        "4                     None                    NaN                        NaN   \n",
        "5                     None                    NaN                        NaN   \n",
        "6                     None                    NaN                        NaN   \n",
        "7                     None                    NaN                        NaN   \n",
        "8                     None                    NaN                        NaN   \n",
        "9                     None                    NaN                        NaN   \n",
        "10                    None                    NaN                        NaN   \n",
        "11                    None                    NaN                        NaN   \n",
        "12                    None                    NaN                        NaN   \n",
        "13                    None                    NaN                        NaN   \n",
        "14                    None                    NaN                        NaN   \n",
        "15                    None                    NaN                        NaN   \n",
        "16                    None                    NaN                        NaN   \n",
        "17                    None                    NaN                        NaN   \n",
        "18                    None                    NaN                        NaN   \n",
        "19                    None                    NaN                        NaN   \n",
        "20                    None                    NaN                        NaN   \n",
        "21                    None                    NaN                        NaN   \n",
        "22                    None                    NaN                        NaN   \n",
        "23                    None                    NaN                        NaN   \n",
        "24                    None                    NaN                        NaN   \n",
        "25                    None                    NaN                        NaN   \n",
        "26                    None                    NaN                        NaN   \n",
        "27                    None                    NaN                        NaN   \n",
        "28                    None                    NaN                        NaN   \n",
        "29                    None                    NaN                        NaN   \n",
        "30                    None                    NaN                        NaN   \n",
        "31                    None                    NaN                        NaN   \n",
        "32                    None                    NaN                        NaN   \n",
        "33                    None                    NaN                        NaN   \n",
        "34                    None                    NaN                        NaN   \n",
        "35                    None                    NaN                        NaN   \n",
        "36                    None                    NaN                        NaN   \n",
        "37                    None                    NaN                        NaN   \n",
        "38                    None                    NaN                        NaN   \n",
        "39                    None                    NaN                        NaN   \n",
        "40                    None                    NaN                        NaN   \n",
        "41                    None                    NaN                        NaN   \n",
        "42                    None                    NaN                        NaN   \n",
        "43                    None                    NaN                        NaN   \n",
        "44                    None                    NaN                        NaN   \n",
        "45                    None                    NaN                        NaN   \n",
        "46                    None                    NaN                        NaN   \n",
        "47                    None                    NaN                        NaN   \n",
        "48                    None                    NaN                        NaN   \n",
        "49           GameOfThrones                    NaN                        NaN   \n",
        "50                    None                    NaN                        NaN   \n",
        "51                    None                    NaN                        NaN   \n",
        "52                    None                    NaN                        NaN   \n",
        "53                    None                    NaN                        NaN   \n",
        "54                    None                    NaN                        NaN   \n",
        "55                    None                    NaN                        NaN   \n",
        "56                    None                    NaN                        NaN   \n",
        "57                    None                    NaN                        NaN   \n",
        "58                    None                    NaN                        NaN   \n",
        "59                    None                    NaN                        NaN   \n",
        "                       ...                    ...                        ...   \n",
        "\n",
        "    in_reply_to_user_id  in_reply_to_user_id_str lang place  \\\n",
        "0                   NaN                      NaN   en  None   \n",
        "1                   NaN                      NaN   en  None   \n",
        "2                   NaN                      NaN   en  None   \n",
        "3                   NaN                      NaN   en  None   \n",
        "4                   NaN                      NaN   en  None   \n",
        "5                   NaN                      NaN   en  None   \n",
        "6                   NaN                      NaN   en  None   \n",
        "7                   NaN                      NaN   en  None   \n",
        "8                   NaN                      NaN   en  None   \n",
        "9                   NaN                      NaN   en  None   \n",
        "10                  NaN                      NaN   en  None   \n",
        "11                  NaN                      NaN   en  None   \n",
        "12                  NaN                      NaN   en  None   \n",
        "13                  NaN                      NaN   en  None   \n",
        "14                  NaN                      NaN   en  None   \n",
        "15                  NaN                      NaN   en  None   \n",
        "16                  NaN                      NaN   en  None   \n",
        "17                  NaN                      NaN   en  None   \n",
        "18                  NaN                      NaN   en  None   \n",
        "19                  NaN                      NaN   en  None   \n",
        "20                  NaN                      NaN   en  None   \n",
        "21                  NaN                      NaN   en  None   \n",
        "22                  NaN                      NaN   en  None   \n",
        "23                  NaN                      NaN   en  None   \n",
        "24                  NaN                      NaN   en  None   \n",
        "25                  NaN                      NaN   en  None   \n",
        "26                  NaN                      NaN   en  None   \n",
        "27                  NaN                      NaN   en  None   \n",
        "28                  NaN                      NaN   en  None   \n",
        "29                  NaN                      NaN   en  None   \n",
        "30                  NaN                      NaN   en  None   \n",
        "31                  NaN                      NaN   en  None   \n",
        "32                  NaN                      NaN   en  None   \n",
        "33                  NaN                      NaN   en  None   \n",
        "34                  NaN                      NaN   en  None   \n",
        "35                  NaN                      NaN   en  None   \n",
        "36                  NaN                      NaN   en  None   \n",
        "37                  NaN                      NaN   en  None   \n",
        "38                  NaN                      NaN   en  None   \n",
        "39                  NaN                      NaN   en  None   \n",
        "40                  NaN                      NaN   en  None   \n",
        "41                  NaN                      NaN   vi  None   \n",
        "42                  NaN                      NaN   en  None   \n",
        "43                  NaN                      NaN   en  None   \n",
        "44                  NaN                      NaN   en  None   \n",
        "45                  NaN                      NaN   en  None   \n",
        "46                  NaN                      NaN   en  None   \n",
        "47                  NaN                      NaN   en  None   \n",
        "48                  NaN                      NaN   en  None   \n",
        "49            180463340                180463340   en  None   \n",
        "50                  NaN                      NaN   en  None   \n",
        "51                  NaN                      NaN   en  None   \n",
        "52                  NaN                      NaN   en  None   \n",
        "53                  NaN                      NaN   en  None   \n",
        "54                  NaN                      NaN   en  None   \n",
        "55                  NaN                      NaN   en  None   \n",
        "56                  NaN                      NaN   en  None   \n",
        "57                  NaN                      NaN   en  None   \n",
        "58                  NaN                      NaN   en  None   \n",
        "59                  NaN                      NaN   en  None   \n",
        "                    ...                      ...  ...   ...   \n",
        "\n",
        "   possibly_sensitive  retweet_count retweeted      \n",
        "0               False              0     False ...  \n",
        "1               False              0     False ...  \n",
        "2               False              0     False ...  \n",
        "3               False              0     False ...  \n",
        "4               False              0     False ...  \n",
        "5               False              0     False ...  \n",
        "6               False              0     False ...  \n",
        "7               False              0     False ...  \n",
        "8               False              0     False ...  \n",
        "9               False              0     False ...  \n",
        "10              False              0     False ...  \n",
        "11              False              0     False ...  \n",
        "12              False              0     False ...  \n",
        "13              False              0     False ...  \n",
        "14              False              0     False ...  \n",
        "15              False              0     False ...  \n",
        "16              False              0     False ...  \n",
        "17              False              0     False ...  \n",
        "18              False              0     False ...  \n",
        "19              False              0     False ...  \n",
        "20              False              0     False ...  \n",
        "21               True              0     False ...  \n",
        "22              False              0     False ...  \n",
        "23              False              0     False ...  \n",
        "24              False              0     False ...  \n",
        "25              False              0     False ...  \n",
        "26              False              0     False ...  \n",
        "27              False              0     False ...  \n",
        "28              False              0     False ...  \n",
        "29              False              0     False ...  \n",
        "30              False              0     False ...  \n",
        "31              False              0     False ...  \n",
        "32              False              0     False ...  \n",
        "33              False              0     False ...  \n",
        "34              False              0     False ...  \n",
        "35              False              0     False ...  \n",
        "36              False              0     False ...  \n",
        "37              False              0     False ...  \n",
        "38              False              0     False ...  \n",
        "39              False              0     False ...  \n",
        "40              False              0     False ...  \n",
        "41              False              0     False ...  \n",
        "42              False              0     False ...  \n",
        "43              False              0     False ...  \n",
        "44              False              0     False ...  \n",
        "45              False              0     False ...  \n",
        "46              False              0     False ...  \n",
        "47              False              0     False ...  \n",
        "48              False              0     False ...  \n",
        "49              False              0     False ...  \n",
        "50              False              0     False ...  \n",
        "51              False              0     False ...  \n",
        "52              False              0     False ...  \n",
        "53              False              0     False ...  \n",
        "54              False              0     False ...  \n",
        "55              False              0     False ...  \n",
        "56              False              0     False ...  \n",
        "57              False              0     False ...  \n",
        "58              False              0     False ...  \n",
        "59              False              0     False ...  \n",
        "                  ...            ...       ...      \n",
        "\n",
        "[35038 rows x 25 columns]\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"Some of the items in a data frame may be null values, and these null values can wreak all kinds of havoc during analysis. Once you understand why they exist, it's wise to filter them out if possible. The null values in this collection of tweets are caused by \"limit notices\", which Twitter sends to tell you that you're being rate-limited. Notice in the columnar output above that the \"limit\" field (which is not typically part of a tweet) appears 16 times. This indicates that we received 16 limit notices and means that there are effectively 16 \"rows\" in our data frame that has null values for all of the fields we'd have expected to see.\n",
      "\n",
      "Per the Streaming API guidelines, Twitter will only provide up to 1% of the total volume of the firehose, and anything beyond that is filtered out with each \"limit notice\" telling you how many tweets were filtered out. This means that tweets containing \"Amazon\" accounted for at least 1% of the total tweet volume at the time this data was being collected. The next cell shows how to \"pop\" off the column containing the sixteen limit notices and sum up the totals across these limit notices so that we can learn exactly how many tweets were filtered out across the aggregate.\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Observe the \"limit\" field that reflects \"limit notices\" where the streaming API\n",
      "# couldn't return more than 1% of the firehose.\n",
      "# See https://dev.twitter.com/docs/streaming-apis/messages#Limit_notices_limit\n",
      "\n",
      "# Capture the limit notices by indexing into the data frame for non-null field\n",
      "# containing \"limit\"\n",
      "\n",
      "limit_notices = df[pd.notnull(df.limit)]\n",
      "\n",
      "# Remove the limit notice column from the DataFrame entirely\n",
      "\n",
      "df = df[pd.notnull(df['id'])]\n",
      "\n",
      "print \"Number of total tweets that were rate-limited\", sum([ln['track'] for ln in limit_notices.limit])\n",
      "print \"Total number of limit notices\", len(limit_notices)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'DataFrame' object has no attribute 'limit'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-e640c5e81e1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# containing \"limit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlimit_notices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Remove the limit notice column from the DataFrame entirely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1813\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 1815\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'limit'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That appeared to do nothing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's index the tweets by time:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create a time-based index on the tweets for time series analysis\n",
      "# on the created_at field of the existing DataFrame.\n",
      "\n",
      "df.set_index('created_at', drop=False, inplace=True)\n",
      "\n",
      "print \"Created date/time index on tweets\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Created date/time index on tweets\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get a sense of the time range for the data\n",
      "\n",
      "print \"First tweet timestamp (UTC)\", df['created_at'][0]\n",
      "print \"Last tweet timestamp (UTC) \", df['created_at'][-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "First tweet timestamp (UTC) 2014-06-02 00:15:00\n",
        "Last tweet timestamp (UTC)  2014-06-02 01:45:50\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's group the tweets by 15 minute intervals and print them out as a hacky-y histogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's group the tweets by (hour, minute) and look at the overall volumes with a simple\n",
      "# text-based histogram\n",
      "\n",
      "def group_by_15_min_intervals(x):\n",
      "    if   0 <= x.minute <= 15: return (x.hour, \"0-15\")\n",
      "    elif 15 < x.minute <= 30: return (x.hour, \"16-30\")\n",
      "    elif 30 < x.minute <= 45: return (x.hour, \"31-45\")\n",
      "    else: return (x.hour, \"46-00\")\n",
      "\n",
      "\n",
      "grouped = df.groupby(lambda x: group_by_15_min_intervals(x))\n",
      "\n",
      "print \"Number of relevant tweets by intervals (UTC)\"\n",
      "print\n",
      "\n",
      "for interval, group in grouped:\n",
      "    print interval, len(group), \"\\t\", '*'*(len(group) / 200)\n",
      "\n",
      "# Since we didn't start or end precisely on an interval, let's\n",
      "# slice off the extremes. This has the added benefit of also\n",
      "# improving the resolution of the plot that shows the trend\n",
      "plt.plot([len(group) for hour, group in grouped][1:-1])\n",
      "plt.ylabel(\"Tweet Volume\")\n",
      "plt.xlabel(\"Time\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of relevant tweets by intervals (UTC)\n",
        "\n",
        "(0, '0-15') 61 \t\n",
        "(0, '16-30') 972 \t****\n",
        "(0, '31-45') 1676 \t********\n",
        "(0, '46-00') 5720 \t****************************\n",
        "(1, '0-15') 13043 \t*****************************************************************\n",
        "(1, '16-30') 6257 \t*******************************\n",
        "(1, '31-45') 7309 \t************************************\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'plt' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-1cf277cf5fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# slice off the extremes. This has the added benefit of also\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# improving the resolution of the plot that shows the trend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tweet Volume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's group the cells by minute:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's group the tweets by hour and look at the overall volumes with a simple\n",
      "# text-based histogram\n",
      "\n",
      "# First group by the minute\n",
      "\n",
      "grouped = df.groupby(lambda x: x.minute)\n",
      "\n",
      "print \"Number of relevant tweets by the minute (UTC)\"\n",
      "print\n",
      "\n",
      "# You can iterate over the groups and print \n",
      "# out the volume of tweets for each hour \n",
      "# along with a simple text-based histogram\n",
      "\n",
      "for minute, group in grouped:\n",
      "    print minute, len(group), '*'*(len(group) / 100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of relevant tweets by the minute (UTC)\n",
        "\n",
        "0 826 ********\n",
        "1 1004 **********\n",
        "2 1560 ***************\n",
        "3 1487 **************\n",
        "4 1462 **************\n",
        "5 1005 **********\n",
        "6 759 *******\n",
        "7 592 *****\n",
        "8 544 *****\n",
        "9 588 *****\n",
        "10 470 ****\n",
        "11 486 ****\n",
        "12 587 *****\n",
        "13 638 ******\n",
        "14 491 ****\n",
        "15 605 ******\n",
        "16 600 ******\n",
        "17 518 *****\n",
        "18 442 ****\n",
        "19 359 ***\n",
        "20 437 ****\n",
        "21 510 *****\n",
        "22 441 ****\n",
        "23 431 ****\n",
        "24 383 ***\n",
        "25 464 ****\n",
        "26 440 ****\n",
        "27 656 ******\n",
        "28 675 ******\n",
        "29 403 ****\n",
        "30 470 ****\n",
        "31 426 ****\n",
        "32 436 ****\n",
        "33 379 ***\n",
        "34 559 *****\n",
        "35 787 *******\n",
        "36 586 *****\n",
        "37 533 *****\n",
        "38 604 ******\n",
        "39 475 ****\n",
        "40 512 *****\n",
        "41 499 ****\n",
        "42 748 *******\n",
        "43 811 ********\n",
        "44 667 ******\n",
        "45 963 *********\n",
        "46 484 ****\n",
        "47 412 ****\n",
        "48 452 ****\n",
        "49 373 ***\n",
        "50 353 ***\n",
        "51 361 ***\n",
        "52 322 ***\n",
        "53 341 ***\n",
        "54 357 ***\n",
        "55 342 ***\n",
        "56 403 ****\n",
        "57 449 ****\n",
        "58 500 *****\n",
        "59 571 *****\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try a better way of grouping by (hour, minute):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's group the tweets by (hour, minute) and look at the overall volumes with a simple\n",
      "# text-based histogram\n",
      "\n",
      "def group_by_hr_min_intervals(x):\n",
      "    return (x.hour, x.minute)\n",
      "#     if   0 <= x.minute <= 15: return (x.hour, \"0-15\")\n",
      "#     elif 15 < x.minute <= 30: return (x.hour, \"16-30\")\n",
      "#     elif 30 < x.minute <= 45: return (x.hour, \"31-45\")\n",
      "#     else: return (x.hour, \"46-00\")\n",
      "\n",
      "\n",
      "grouped = df.groupby(lambda x: group_by_hr_min_intervals(x))\n",
      "\n",
      "print \"Number of relevant tweets by intervals (UTC)\"\n",
      "print \"First tweet timestamp (UTC)\", df['created_at'][0]\n",
      "print\n",
      "\n",
      "for interval, group in grouped:\n",
      "    print interval, len(group), \"\\t\", '*'*(len(group) / 20)\n",
      "\n",
      "print \"Last tweet timestamp (UTC) \", df['created_at'][-1]\n",
      "\n",
      "# Since we didn't start or end precisely on an interval, let's\n",
      "# slice off the extremes. This has the added benefit of also\n",
      "# improving the resolution of the plot that shows the trend\n",
      "# plt.plot([len(group) for hour, group in grouped][1:-1])\n",
      "# plt.ylabel(\"Tweet Volume\")\n",
      "# plt.xlabel(\"Time\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of relevant tweets by intervals (UTC)\n",
        "First tweet timestamp (UTC) 2014-06-02 00:15:00\n",
        "\n",
        "(0, 15) 61 \t***\n",
        "(0, 16) 50 \t**\n",
        "(0, 17) 66 \t***\n",
        "(0, 18) 64 \t***\n",
        "(0, 19) 52 \t**\n",
        "(0, 20) 64 \t***\n",
        "(0, 21) 64 \t***\n",
        "(0, 22) 69 \t***\n",
        "(0, 23) 55 \t**\n",
        "(0, 24) 58 \t**\n",
        "(0, 25) 79 \t***\n",
        "(0, 26) 75 \t***\n",
        "(0, 27) 61 \t***\n",
        "(0, 28) 60 \t***\n",
        "(0, 29) 59 \t**\n",
        "(0, 30) 96 \t****\n",
        "(0, 31) 80 \t****\n",
        "(0, 32) 75 \t***\n",
        "(0, 33) 68 \t***\n",
        "(0, 34) 67 \t***\n",
        "(0, 35) 73 \t***\n",
        "(0, 36) 68 \t***\n",
        "(0, 37) 63 \t***\n",
        "(0, 38) 73 \t***\n",
        "(0, 39) 62 \t***\n",
        "(0, 40) 75 \t***\n",
        "(0, 41) 95 \t****\n",
        "(0, 42) 91 \t****\n",
        "(0, 43) 91 \t****\n",
        "(0, 44) 138 \t******\n",
        "(0, 45) 557 \t***************************\n",
        "(0, 46) 484 \t************************\n",
        "(0, 47) 412 \t********************\n",
        "(0, 48) 452 \t**********************\n",
        "(0, 49) 373 \t******************\n",
        "(0, 50) 353 \t*****************\n",
        "(0, 51) 361 \t******************\n",
        "(0, 52) 322 \t****************\n",
        "(0, 53) 341 \t*****************\n",
        "(0, 54) 357 \t*****************\n",
        "(0, 55) 342 \t*****************\n",
        "(0, 56) 403 \t********************\n",
        "(0, 57) 449 \t**********************\n",
        "(0, 58) 500 \t*************************\n",
        "(0, 59) 571 \t****************************\n",
        "(1, 0) 826 \t*****************************************\n",
        "(1, 1) 1004 \t**************************************************\n",
        "(1, 2) 1560 \t******************************************************************************\n",
        "(1, 3) 1487 \t**************************************************************************\n",
        "(1, 4) 1462 \t*************************************************************************\n",
        "(1, 5) 1005 \t**************************************************\n",
        "(1, 6) 759 \t*************************************\n",
        "(1, 7) 592 \t*****************************\n",
        "(1, 8) 544 \t***************************\n",
        "(1, 9) 588 \t*****************************\n",
        "(1, 10) 470 \t***********************\n",
        "(1, 11) 486 \t************************\n",
        "(1, 12) 587 \t*****************************\n",
        "(1, 13) 638 \t*******************************\n",
        "(1, 14) 491 \t************************\n",
        "(1, 15) 544 \t***************************\n",
        "(1, 16) 550 \t***************************\n",
        "(1, 17) 452 \t**********************\n",
        "(1, 18) 378 \t******************\n",
        "(1, 19) 307 \t***************\n",
        "(1, 20) 373 \t******************\n",
        "(1, 21) 446 \t**********************\n",
        "(1, 22) 372 \t******************\n",
        "(1, 23) 376 \t******************\n",
        "(1, 24) 325 \t****************\n",
        "(1, 25) 385 \t*******************\n",
        "(1, 26) 365 \t******************\n",
        "(1, 27) 595 \t*****************************\n",
        "(1, 28) 615 \t******************************\n",
        "(1, 29) 344 \t*****************\n",
        "(1, 30) 374 \t******************\n",
        "(1, 31) 346 \t*****************\n",
        "(1, 32) 361 \t******************\n",
        "(1, 33) 311 \t***************\n",
        "(1, 34) 492 \t************************\n",
        "(1, 35) 714 \t***********************************\n",
        "(1, 36) 518 \t*************************\n",
        "(1, 37) 470 \t***********************\n",
        "(1, 38) 531 \t**************************\n",
        "(1, 39) 413 \t********************\n",
        "(1, 40) 437 \t*********************\n",
        "(1, 41) 404 \t********************\n",
        "(1, 42) 657 \t********************************\n",
        "(1, 43) 720 \t************************************\n",
        "(1, 44) 529 \t**************************\n",
        "(1, 45) 406 \t********************\n",
        "Last tweet timestamp (UTC)  2014-06-02 01:45:50\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "D3-ready csv"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Let's group the tweets by (hour, minute) and look at the overall volumes with a simple\n",
      "# text-based histogram\n",
      "\n",
      "def group_by_hr_min_intervals(x):\n",
      "    return (x.hour, x.minute)\n",
      "#     if   0 <= x.minute <= 15: return (x.hour, \"0-15\")\n",
      "#     elif 15 < x.minute <= 30: return (x.hour, \"16-30\")\n",
      "#     elif 30 < x.minute <= 45: return (x.hour, \"31-45\")\n",
      "#     else: return (x.hour, \"46-00\")\n",
      "\n",
      "\n",
      "grouped = df.groupby(lambda x: group_by_hr_min_intervals(x))\n",
      "\n",
      "print \"Number of relevant tweets by intervals (UTC)\"\n",
      "# print \"First tweet timestamp (UTC)\", df['created_at'][0]\n",
      "print \"(hour:minute),tweets\"\n",
      "\n",
      "for interval, group in grouped:\n",
      "#     print interval, \"\\t\", len(group)\n",
      "    g = len(group)\n",
      "#     print type(interval)\n",
      "    print \"{0}:{1},{2}\".format(interval[0], interval[1], g)\n",
      "\n",
      "# print \"Last tweet timestamp (UTC) \", df['created_at'][-1]\n",
      "\n",
      "# Since we didn't start or end precisely on an interval, let's\n",
      "# slice off the extremes. This has the added benefit of also\n",
      "# improving the resolution of the plot that shows the trend\n",
      "# plt.plot([len(group) for hour, group in grouped][1:-1])\n",
      "# plt.ylabel(\"Tweet Volume\")\n",
      "# plt.xlabel(\"Time\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of relevant tweets by intervals (UTC)\n",
        "(hour, minute),tweets\n",
        "0:15,61\n",
        "0:16,50\n",
        "0:17,66\n",
        "0:18,64\n",
        "0:19,52\n",
        "0:20,64\n",
        "0:21,64\n",
        "0:22,69\n",
        "0:23,55\n",
        "0:24,58\n",
        "0:25,79\n",
        "0:26,75\n",
        "0:27,61\n",
        "0:28,60\n",
        "0:29,59\n",
        "0:30,96\n",
        "0:31,80\n",
        "0:32,75\n",
        "0:33,68\n",
        "0:34,67\n",
        "0:35,73\n",
        "0:36,68\n",
        "0:37,63\n",
        "0:38,73\n",
        "0:39,62\n",
        "0:40,75\n",
        "0:41,95\n",
        "0:42,91\n",
        "0:43,91\n",
        "0:44,138\n",
        "0:45,557\n",
        "0:46,484\n",
        "0:47,412\n",
        "0:48,452\n",
        "0:49,373\n",
        "0:50,353\n",
        "0:51,361\n",
        "0:52,322\n",
        "0:53,341\n",
        "0:54,357\n",
        "0:55,342\n",
        "0:56,403\n",
        "0:57,449\n",
        "0:58,500\n",
        "0:59,571\n",
        "1:0,826\n",
        "1:1,1004\n",
        "1:2,1560\n",
        "1:3,1487\n",
        "1:4,1462\n",
        "1:5,1005\n",
        "1:6,759\n",
        "1:7,592\n",
        "1:8,544\n",
        "1:9,588\n",
        "1:10,470\n",
        "1:11,486\n",
        "1:12,587\n",
        "1:13,638\n",
        "1:14,491\n",
        "1:15,544\n",
        "1:16,550\n",
        "1:17,452\n",
        "1:18,378\n",
        "1:19,307\n",
        "1:20,373\n",
        "1:21,446\n",
        "1:22,372\n",
        "1:23,376\n",
        "1:24,325\n",
        "1:25,385\n",
        "1:26,365\n",
        "1:27,595\n",
        "1:28,615\n",
        "1:29,344\n",
        "1:30,374\n",
        "1:31,346\n",
        "1:32,361\n",
        "1:33,311\n",
        "1:34,492\n",
        "1:35,714\n",
        "1:36,518\n",
        "1:37,470\n",
        "1:38,531\n",
        "1:39,413\n",
        "1:40,437\n",
        "1:41,404\n",
        "1:42,657\n",
        "1:43,720\n",
        "1:44,529\n",
        "1:45,406\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
} 
